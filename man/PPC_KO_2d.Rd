% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PPC_KO_Rinterface.R
\name{PPC_KO_2d}
\alias{PPC_KO_2d}
\title{PPC_KO_2d}
\arguments{
\item{X}{\strong{\verb{numeric matrix}}. Each row (m) represents a point of the domain in which the surface is evaluated.
The surface is represented by a grid, of dimensions (m1,m2), such that their product is m.
Then, the grid is encapsulated into a vector, column after column. Each column (n) represents a time instant.
Some auxiliary functions (\link{data_2d_wrapper_from_list}, \link{data_2d_wrapper_from_array}) are available for wrapping data into a coherent data structure for the algorithm.}

\item{id_CV}{\strong{\code{string}} (default: \strong{\code{"NoCV"}}). Which version of PPCKO is performed.
\itemize{
\item "NoCV": PPCKO is performed with the parameters passed as input;
\item "CV_alpha": cv for regularization parameter is performed;
\item "CV_k": cv for the number of retained PPCs is performed;
\item "CV": cv for both the regularization parameter and the number of retained PPCs is performed.
}}

\item{alpha}{\strong{\code{double}} (default: \strong{\code{0.75}}). Strictly positive. Regularization parameter. Will be ignored in "CV_alpha" and "CV" versions.}

\item{k}{\strong{\code{integer}} (default: \strong{\code{0}}). Between 0 and the number of available discrete evaluations of the curve (m).
Number of retained PPCs. Will be ignored in "CV_k" and "CV" versions. If "NoCV" and "CV_alpha" versions:
if it is 0: the number of PPCs retained is chosen through the level of explanatory power criterion (see next parameter);
if it is greater than 0: the number of PPCs retained is k.}

\item{threshold_ppc}{\strong{\code{double}} (default: \strong{\code{0.95}}). Between 0 and 1. Threshold of explanatory power retained. Will be ignored in "CV_k" and "CV" versions,
and in "NoCV" and "CV_alpha" if k>0. Otherwise, determines the number of PPCs retained depending on data information.}

\item{alpha_vec}{\strong{\verb{numeric vector}} (default: \strong{\code{NULL}}). The input space for the regularization parameter in "CV_alpha" and "CV"
versions. If NULL: logarithmic scale with increasing exponent from 1e-10 up to 1e11 is the input space.}

\item{k_vec}{\strong{\verb{integer vector}} (default: \strong{\code{NULL}}). The input space for the number of retained PPCs in "CV_k" and "CV" versions.
If NULL: input space are the integer from 1 up to m.}

\item{toll}{\strong{\code{double}} (default: \strong{\code{1e-4}}). If doing cv for the number of PPCs, by PPCKO construction, adding a PPC can not improve anymore
the predictor. Tolerance for stopping adding PPCs in the cv, evaluated as toll*trace(covariance).}

\item{disc_ev_x1}{\strong{\verb{numeric vector}} (default: \strong{\code{NULL}}). Has to have size m1. The points of the domain for which the evaluation is available along dimension one.
If NULL: a discrete equally spaced grid with m1 points is assumed.}

\item{num_disc_ev_x1}{\strong{\code{integer}} (default: \strong{\code{10}}). The number of discrete evaluations along dimension one (has to be m1). \strong{\verb{IMPORTANT TO PASS IT CORRECTLY}}.}

\item{disc_ev_x2}{\strong{\verb{numeric vector}} (default: \strong{\code{NULL}}). Has to have size m2. The points of the domain for which the evaluation is available along dimension two.
If NULL: a discrete equally spaced grid with m2 points is assumed.}

\item{num_disc_ev_x2}{\strong{\code{integer}} (default: \strong{\code{10}}). The number of discrete evaluations along dimension two (has to be m2). \strong{\verb{IMPORTANT TO PASS IT CORRECTLY}}.}

\item{left_extreme_x1}{\strong{\code{double}} (default: \strong{\code{0}}). Left extreme of the domain of the functional object along dimension one.}

\item{right_extreme_x1}{\strong{\code{double}} (default: \strong{\code{1}}). Right extreme of the domain of the functional object along dimension one.}

\item{left_extreme_x2}{\strong{\code{double}} (default: \strong{\code{0}}). Left extreme of the domain of the functional object along dimension two.}

\item{right_extreme_x2}{\strong{\code{double}} (default: \strong{\code{1}}). Right extreme of the domain of the functional object along dimension two.}

\item{min_size_ts}{\strong{\code{integer}} (default: \strong{\code{NULL}}). Between 2 and max_size_ts. The dimension (number of time instants) of the first training set.
If NULL: is half of n if n even, ceil of half of n if n odd.}

\item{max_size_ts}{\strong{\code{integer}} (default: \strong{\code{NULL}}). Between min_size_ts and n-1. The dimension (number of time instants) of the last training set.
If NULL: n-1.}

\item{err_ret}{\strong{\code{bool}} (default: \strong{\code{FALSE}}).
\itemize{
\item FALSE: validation errors are not returned (and not stored during the algorithm);
\item TRUE: validation errors are returned;
}}

\item{ex_solver}{\strong{\code{bool}} (default: \strong{\code{TRUE}}).
\itemize{
\item FALSE: using GEP to retrieve PPCs (more efficient, but losing PPCs' explanatory power interpretation). Cannot be used if "k" found through explanatory power criterion;
\item TRUE: solving PPCKO exactly;
}}

\item{num_threads}{\strong{\code{integer}} (default: \strong{\code{NULL}}). Number of threads for going parallel multithreading.
Using 1 is equivalent to run the algorithm sequentially (not recommended if doing cv).
If NULL, or a wrong integer is passed, by default the number of threads used will be equal to the maximum number of threads available for the machine.}

\item{id_rem_nan}{\strong{\code{string}} (default: \strong{\code{NULL}}). Strategy for handling NaNs values. The NaNs are substitute
only if the row contains other value that are not NaNs, if not the evaluation is interpreted as not belonging
to the domain (strategy for handling more complex domains).
\itemize{
\item "NO": NaNs are not replaced (\strong{N.B.:  DO NOT USE IT});
\item "MR": NaNs are replaced by the avergage of the non-NaNs values of the row (default);
\item "ZR": NaNs are replaced by 0.
}}
}
\value{
\strong{\code{list}} whose items are:
\itemize{
\item 'One-step ahead prediction': \strong{\verb{numeric matrix}}: numeric matrix with the predicted surface;
\item 'Alpha': \strong{\code{double}}: regularization parameter used;
\item 'Number of PPCs retained': \strong{\code{integer}}: number of retained PPCs;
\item 'Scores along PPCs': \strong{\verb{numeric vector}}: scores along every PPC. Projection of the last instant over the direction of the PPC;
\item 'Explanatory power PPCs': \strong{\verb{numeric vector}}: the cumulative explanatory power up to the PPC i-th;
\item 'Directions of PPCs': \strong{\verb{list of numeric matrix}}: each element of the list is i-th PPC's direction;
\item 'Weights of PPCs': \strong{\verb{list of numeric matrix}}: each element of the list is i-th PPC's weight;
\item 'Sd scores directions': \strong{\verb{numeric vector}}: size equal to the number of retained PPCs: each element is the standard deviation of the scalar products within function from instant 2 to instant n and the direction of PPC i-th;
\item 'Sd scores weights': \strong{\verb{numeric vector}}: size equal to the number of retained PPCs: each element is the standard deviation of the scalar products within function from instant 1 to instant n-1 and the weight of PPC i-th;
\item 'Mean function': \strong{\verb{numeric matrix}}. Mean function of the functional time series;
\item 'Validation errors': \strong{\verb{numeric vector}} or \strong{\verb{numeric matrix}}: available only if err_ret==1. For "CV_alpha" and "CV_k"
is a vector containing the validation errors for every parameter (for number of PPCs, it is truncated
to the number of PPCs actually tested in the cv process). For "CV" is a matrix, for each pair alpha (row) - k (col);
\item 'Function discrete evaluations points dim1': the points of the domain for which the evaluations are available along dimension one;
\item 'Left extreme domain dim1': left extreme domain for dimension one;
\item 'Right extreme domain dim1': right extreme domain for dimension one;
\item 'Function discrete evaluations points dim2': the points of the domain for which the evaluations are available along dimension two;
\item 'Left extreme domain dim2': left extreme domain for dimension two;
\item 'Right extreme domain dim2': right extreme domain for dimension two;
\item 'f_n': surface at the last instant;
\item 'CV': which algorithm version has been performed;
\item 'Alphas': input space for the regularization parameter;
\item 'K_s': input space for the number of PPCs retained.
}
}
\description{
Performs Principal Components Analysis Kargin-Onatski algorithm to compute one-step
ahead prediction of Functional time series of surfaces.
CV is eventually performed taking an initial training set, and as validation set the next time instant.
Then, the training set is shifted incrementally by one instant at each iteration, and so the validation set.
The validation error is the average of the estimate of the squared error between prediction and validation set.
}
\details{
If more complex domains have to represented, a row of NaNs is put for specific points that do not belong
to the domain but is important to report anyway (for example, to represent a complicated geographical area)
}
\references{
\itemize{
\item Paper: \href{https://core.ac.uk/download/pdf/82625156.pdf}{Principal Predictive Components Kargin-Onatski algorithm}
\item Source code: \href{https://github.com/AndreaEnricoFranzoni/PPCforAutoregressiveOperator}{PPCKO implementation}
}
}
\seealso{
\link{data_2d_wrapper_from_list}, \link{data_2d_wrapper_from_array}
}
\author{
Andrea Enrico Franzoni
}
